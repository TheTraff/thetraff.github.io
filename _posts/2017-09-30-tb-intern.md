---
layout: post
title:  "How I Spent My Summer"
date:   2017-09-30 00:10:45
categories: experience
---
During my time at TicketBiscuit as an intern, I had the opportunity to work on a project that would get significant use from the company's customers, albeit without them knowing about it. Because of this, the code had be very reliable, which is why we went with an all AWS architecture.

The project consisted of creating a dynamic image resizing API that could be used for images on print-at-home tickets. The main idea was to put an AWS lambda function that took an image from storage, resized it to the desired size, and return that from an API call. Below you'll get my full breakdown of each part of the project, along with some personal thoughts.

## Assembling the Technologies

Before I really get into the meat of things, I will mention that almost everything I used for my part of the project was new to me. Including the AWS components, .NET/C#, and even Windows Powershell. Because of this, the project had somewhat of a slow start in order to get aquatinted with all of the technologies we would be using.

#### AWS lambda
If you're not familiar with AWS lambda functions, they are (usually) simple functions that are run only when triggered by a certain event, such as an API call, an item added to storage, or other event triggers. They are typically used in order to create a "serverless" architecture. I put that in quotes because technically it's not serverless per se, but the person who set up the function doesn't have to actually worry about a server. This is the main draw of lambda functions, that they allow code that is only executed sparsely to not be a continuously running web service. If you're interested in reading more about lambda functions, make sure to check out the docs [here](lambda-docs).

#### API Gateway

In order to trigger the lambda function, we needed to be able to simply use a URL to access the resized image. For example, if the image with id '9999' was needed at size 300x300, then it would simply be *example.url/9999/300/300*. In order to do this, we used API gateway to create an API that would take the url parameters and trigger a lambda function with the url parameters, and return the newly resized image. Feel free to read more about API gateway [here](api-gateway-docs).

#### Cloudfront

An important feature of  the old service was the caching ability. Since ticket layouts were the same for every customer, there would be a large amount of calls to the same url for each customer accessing that ticket. There was no reason to call the lambda function for every one of these calls, as it would be unneeded computation. Unfortunately, the caching ability of API gateway by itself was minimal at the time. In order to solve this, we added yet another layer to the project: an AWS Cloudfront distribution. With this, we were able to cache each API call and not have to worry about unneeded calls to the lambda function. If you're interested in more, check out the [docs](cloudfront-docs).

#### AWS S3

Last, but certainly not least, is the image storage. Keeping with the theme of AWS services, we decided to use an S3 bucket to store all of the client uploaded images. Before we migrated the images to S3, they were stored on a Rackspace cloud server, so we had to transfer about 25 GB of image files. I'll get more into that in a later section. If you want to read more about S3, check it out [here](S3-docs).

--------

After making a final decision on how the project architecture would look, and how all of the parts would be implemented, it was time to get down to business. This was the part I was waiting for the most in fact. While I know it's important to plan out and properly design projects before you, I had been itching to just getting straight to the programming part. I held myself back though, and it paid off since by the time we started programming, we knew exactly what the scope of our required work was.

## Old Code + New Framework = FUN
  The old version of this project involved a .NET project written in C#, and we wanted to be able to reuse as much code as possible. Luckily AWS lambda supports using C# projects, but only in .NET core. .NET core is an open source, cross platform version of the .NET framework. This was one of the first challenges,
  as .NET core was relatively new at the time, and Lambda's support for it was even newer. If you want to read more about .NET core check it out [here](.net-core). Before I get to the trouble that caused us, I'll first talk about the process of going though the old code and looking for parts that we could salvage for the new version.

  As is usually the case with getting aquatinted with large projects, it took a bit of time to decipher what and *where* all the code was that was responsible for resizing images. I'll spare you the details and jump straight to the end: we decided the best way to proceed was to reuse just the part of the code that was responsible for doing the actual resizing work. I should note at this point, that in this post I'm only speaking about the part of the project I was responsible for. The person I was working with was responsible for taking care of the image upload process by clients, while I took care of the image processing and API.

  Armed with some actual code now, I set out to create a lambda function that, when supplied an "image ID" (more on this later), and a size, it would return that image at that size. Luckily since we had decided to use all AWS services, it was incredibly easy to retrieve images from the S3 bucket. After some time, I had something that met the minimum requirements of my part of the project.

#### .NET core difficulties

As I mentioned earlier, .NET core is a cross platform framework and relatively young, which means some of the .NET libraries used by the old project were either not supported or implemented differently in .NET core. When I started creating the lambda function, I had thought this would be a big problem, but it didn't make the project *too* much more difficult thankfully. Mainly because the primary libraries I needed to use were AWS libraries. The biggest problem was that my version of the project had an issue with anti-aliasing when scaling images to smaller sizes. This fix was fairly simple, as all I had to do was change the image processing library I was using and a couple of function calls.

## Putting the Pieces Together

So with the core part of the project (mostly) working, I needed to make it accessible with an API call, and set it up on a Cloudfront distribution in order to take advantage of its caching abilities. I think the term "deceptively easy," is a good way to describe setting up API gateway in front of a lambda function. It's easy to set up the gateway to point to the function, but to get it to work properly, at least with images, is a whole other story. It took a lot of fiddling with what value to return from the lambda function and how to interpret that result on the API side. After an indeterminate amount of fiddling, I finally got to where one could use the url: example.url/9999/300/300 to access the resized image.

The next step from here was setting up the Cloudfront distribution to point to the API gateway. Fortunately this step was much simpler than the previous. It still required some fiddling, but not nearly as much. So now with the main architecture completed on my end, all I had left was to refine and test the system and move all the images from Rackspace Storage to an S3 bucket. Now this may sound fairly simple, but you'd be surprised.

#### Moving to a Different Cloud

So, with 25 Gb of images, I set out to find the best way to move them over. I mentioned earlier about how we needed the url to accept an "image ID," and this is where that fact caused the most trouble. In the SQL database, every file that clients upload, including images, is stored with a "file ID." This is where the confusion came from. And I mean really, really confusing. We spent a lot of time talking about this aspect of the project, which we didn't anticipate was going to be a problem when we were designing it.  We initially thought that, since the url used an "image ID," that it would be easier    At first I wrote a rudimentary Powershell script to download a an image file from the Rackspace server and then upload that file to the S3 bucket, and then delete the local file. I mentioned earlier about  As you can imagine, this would take quite a while to upload all the images. Being the impatient person I am, I started searching for a faster way to finish the task at hand. I came across a python script that took advantage of multithreading to download and upload many files at one time.




[lambda-docs]: http://docs.aws.amazon.com/lambda/latest/dg/welcome.html
[api-gateway-docs]: http://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html
[cloudfront-docs]: http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html
[S3-docs]: http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html
[.net-core]: https://docs.microsoft.com/en-us/dotnet/core/
